# LLM Provider Configuration
# Choose "openai", "claude", or "ollama"
LLM_PROVIDER=ollama

# OpenAI Configuration (if using LLM_PROVIDER=openai)
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL=gpt-3.5-turbo

# Anthropic/Claude Configuration (if using LLM_PROVIDER=claude)
ANTHROPIC_API_KEY=your-anthropic-api-key-here
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# Ollama Configuration (if using LLM_PROVIDER=ollama)
# Note: Requires Ollama to be installed and running locally
# Install from: https://ollama.ai
OLLAMA_MODEL=llama3.2
OLLAMA_BASE_URL=http://localhost:11434

# Model Parameters
TEMPERATURE=0.7

# Database Configuration
# Choose "sqlite" (default, for local development) or "dynamodb" (for AWS deployment)
DATABASE_TYPE=sqlite

# SQLite Configuration (if using DATABASE_TYPE=sqlite)
# SQLALCHEMY_DATABASE_URI=sqlite:///tools.db

# DynamoDB Configuration (if using DATABASE_TYPE=dynamodb)
# Set automatically by Lambda environment, or configure manually:
# DYNAMODB_TABLE_NAME=personal-assistant-tools
